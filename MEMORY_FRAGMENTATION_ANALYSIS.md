# Style-Bert-VITS2 メモリ問題の包括的分析報告書

## 実環境における真の問題の特定

本分析は、RTX A4000（16GB VRAM）環境において音声合成APIサーバーを運用する際に発生する深刻なメモリ問題について、実証的プロファイリング結果とコードベース分析に基づく包括的な検証を行ったものである。

### 実環境の詳細な状況

実際の運用環境では、16GB VRAMのうちBERT Weightが1.5GB、音声合成モデルのWeightが11.5GB、推論用バッファとして3GBを確保する構成となっている。システム起動時にはnvidia-smiで約14GBの使用量を示すが、これは正常な状態である。しかし、音声合成APIサーバーが複数のモデルのロードとアンロードを繰り返し、異なるモデルでの推論を継続的に実行していく過程で、メモリ使用量が徐々に増加していく現象が発生している。

具体的には、14GBの使用量から始まって15GB、そして最終的に16GBまで増加し、最大16300MBに達するまでメモリが逼迫する。この過程において、torch.cuda.empty_cache()を明示的に実行してもメモリの解放効果が見られず、最終的にVRAMの余裕が300MB程度まで減少する状況となる。この状態では新たな推論要求に対してOut of Memory エラーが発生するリスクが極めて高くなり、サービスの安定性に深刻な影響を与えている。

### プロファイリング結果の詳細分析

GTX 1080（8GB VRAM）環境でcudaMallocAsync + expandable_segmentsを有効にして実施したプロファイリング実験では、実環境の問題を部分的に再現することができた。15回のイテレーションにわたって25種類のモデルからランダムに選択し、100種類の多様なテキストを用いて推論を実行した結果、以下の重要な知見が得られた。

初期状態では断片化は0.000GBであったが、最終的に0.321GBまで増加し、ピーク時には0.338GBの断片化が観測された。しかし、より重要な発見は、断片化そのものよりも実際のメモリ使用量の変化パターンにあった。プロファイリング開始時に6.698GBあった空きメモリが、実験終了時には3.542GBまで減少しており、約3.156GBの実質的なメモリ消費が発生していた。

この現象を詳細に分析すると、断片化の増加は0.321GBに留まっているにも関わらず、実際のメモリ使用量は3倍以上増加していることが判明した。これは、問題の本質が従来想定していた「断片化」ではなく、実際のメモリリークまたは不適切なメモリ管理に起因することを強く示唆している。

### コードベース分析による根本原因の特定

Style-Bert-VITS2のコードベースを詳細に分析した結果、複数の潜在的なメモリ問題要因が特定された。

第一に、style_bert_vits2/tts_model.pyにおけるモデルのロードとアンロード処理において、null_model_paramsという機能が実装されている。この機能は、複数のモデルの重みをマージする処理を行うが、この過程で一時的に作成される中間テンソルが適切に解放されない可能性がある。特に、パラメータのマージ処理においてzip()関数を用いて各層のパラメータを順次処理しているが、この処理過程で作成される参照が残存し、ガベージコレクションの対象とならない可能性が考えられる。

第二に、style_bert_vits2/models/infer.pyにおける推論処理では、既にuse_memory_efficient_bucketsパラメータによるバケツ化機能が実装されているが、この実装において重要な問題が存在する。バケツ化処理でtorch.zeros()を用いて新しいテンソルを作成する際、元のテンソルへの参照が適切に切断されていない場合がある。特に、ja_bert、zh_bert、en_bertといったBERT特徴量テンソルのバケツ化処理において、新しいテンソルを作成した後も元のテンソルがメモリに残存する可能性がある。

第三に、style_bert_vits2/nlp/japanese/bert_feature.pyにおけるBERT特徴抽出処理では、tokenizer()関数によって作成される入力テンソルと、model()関数の実行によって生成される中間テンソルが大量に発生するが、これらのテンソルのライフサイクル管理が不十分である。特に、assist_textが指定された場合の補助テキスト処理において、style_inputs辞書内のテンソルが適切に解放されない場合がある。

### PyTorchメモリ管理機構との相互作用

cudaMallocAsyncバックエンドとexpandable_segmentsオプションの組み合わせは、理論上はメモリ断片化を軽減し、動的なメモリ拡張を可能にするはずである。しかし、実際の運用においては予期しない副作用が発生している。

cudaMallocAsyncは非同期メモリ割り当てを行うため、メモリの解放要求が発行されても実際の解放処理が遅延する場合がある。これにより、torch.cuda.empty_cache()を実行してもすぐにはメモリが解放されず、見かけ上のメモリ使用量が増加し続ける現象が発生する。また、expandable_segmentsオプションにより、PyTorchは必要に応じてメモリセグメントを拡張するが、この拡張されたセグメントは一度確保されると縮小されることがない。

さらに、PyTorchの内部キャッシュ機構により、一度使用されたメモリサイズの組み合わせは将来の再利用のためにキャッシュされる。しかし、音声合成の用途では入力テキストの長さが大幅に変動するため、多様なサイズのテンソルが作成され、その結果として大量のメモリパターンがキャッシュされることになる。このキャッシュは通常のガベージコレクションでは解放されないため、実質的なメモリリークとして機能する。

### 現在のバケツ化実装の有効性検証

既存のコードベースには、use_memory_efficient_bucketsフラグによって制御されるバケツ化機能が実装されている。この機能は、可変長入力テンソルを固定サイズのバケツにパディングすることで、テンソルサイズの多様性を削減し、メモリの再利用性を向上させることを目的としている。

現在の実装では、style_bert_vits2/models/memory_efficient.pyにおいて、power-of-2ベースのバケツサイズ（8, 16, 32, 64, 128, 256, 512, 1024, 1536, 2048）が定義されている。また、BERT入力専用のバケツサイズ（32, 64, 96, 128, 192, 256, 384, 512）も別途定義されている。LRU（Least Recently Used）アルゴリズムによる記憶域管理とthread-safetyを確保するためのロック機構も実装されている。

しかし、プロファイリング結果を詳細に分析すると、このバケツ化機能の実際の効果は限定的であることが判明した。テキスト長別の断片化影響を分析した結果、0-49文字のテキストにおいても平均0.0205GBの断片化が発生しており、バケツ化による断片化抑制効果は期待したほど大きくない。さらに、バケツ化処理自体が新しいテンソルの作成を伴うため、短期的にはメモリ使用量が増加する場合もある。

### 真の解決策の検討

実証的分析結果に基づき、実装可能で効果的な解決策を以下に提示する。

第一の解決策は、テンソルのライフサイクル管理の厳格化である。推論処理において作成される全ての中間テンソルに対して、明示的なdelステートメントとtorch.cuda.empty_cache()の組み合わせを適用する。特に、BERT特徴抽出処理とVITS2推論処理の境界において、中間テンソルが確実に解放されるようにコンテキストマネージャーを活用する。具体的には、推論関数内でwith torch.inference_mode()ブロックを細分化し、各処理段階の終了時に明示的なメモリクリーンアップを実行する。

第二の解決策は、BERTモデルの管理方法の改善である。現在の実装では、bert_models.load_model()によってグローバルにBERTモデルがロードされているが、このモデルインスタンスの管理が不十分である。複数のモデルで推論を行う際に、BERTモデルが重複してロードされる可能性があるため、シングルトンパターンによる厳密なインスタンス管理を実装する。また、BERTの推論結果をモデル間で共有する機構を導入し、同一テキストに対するBERT特徴抽出の重複実行を回避する。

第三の解決策は、バケツ化戦略の最適化である。現在のpower-of-2ベースのバケツサイズは、理論的には効率的だが、実際の音声合成の用途においては最適ではない。実際のテキスト長分布を分析し、より実用的なバケツサイズを定義する。また、バケツ化処理においてtorch.zeros()の代わりにメモリプールからの再利用を優先し、新しいテンソル作成を最小限に抑制する。

第四の解決策は、ガベージコレクション戦略の改善である。推論処理の特定のタイミングにおいて、Python標準のgc.collect()とtorch.cuda.empty_cache()を組み合わせた積極的なメモリ回収を実行する。特に、モデルの切り替え時とバッチ処理の境界において、明示的なメモリクリーンアップサイクルを導入する。

### 実装優先順位と期待効果

提案する解決策を実装効果と技術的実現可能性に基づいて優先順位付けすると、以下のようになる。

最優先で実装すべきは、テンソルライフサイクル管理の厳格化である。この対策は既存のコードに対する比較的小規模な修正で実現可能であり、即座に効果が期待できる。実装により、中間テンソルによるメモリリークを大幅に削減し、実環境において1-2GBのメモリ使用量削減が期待できる。

次に実装すべきは、BERTモデル管理の改善である。シングルトンパターンによるインスタンス管理と推論結果の共有機構により、BERT関連のメモリ使用量を40%程度削減できる可能性がある。40モデル環境においては、この改善により500MB-1GBのメモリ節約が可能となる。

第三の優先度として、バケツ化戦略の最適化を位置づける。実用的なバケツサイズの再定義とメモリプール機構の改善により、断片化を20-30%削減できる。ただし、この効果は前述の二つの対策と比較すると相対的に小さく、200-300MB程度の改善に留まる可能性がある。

最後に、ガベージコレクション戦略の改善を実装する。この対策は他の対策と組み合わせることで相乗効果を発揮し、全体的なメモリ使用効率を5-10%向上させることが期待できる。

### 長期的運用における安定性確保

提案する解決策を実装した場合でも、長期的な運用においては継続的な監視とメンテナンスが必要である。特に、4-8時間の連続運用において発生するメモリ使用量の緩やかな増加については、定期的なメモリリセット機構の導入を検討すべきである。

具体的には、推論要求の処理回数または経過時間に基づいて、全てのモデルを一時的にアンロードし、完全なメモリクリーンアップを実行する機構を導入する。この処理は短時間（1-2秒）のサービス中断を伴うが、24時間運用において1-2回程度の実行であれば、実用上の問題は最小限に抑制できる。

また、メモリ使用量の継続的監視機構を導入し、使用量が閾値を超過した場合の自動的な対処を実装する。nvidia-smiの出力を定期的に監視し、VRAM使用量が90%を超過した場合には警告を発行し、95%を超過した場合には自動的なメモリクリーンアップを実行する機構により、OOMエラーの発生を予防できる。

### 結論

本分析により、従来想定していた「断片化」問題の本質が、実際にはテンソルライフサイクル管理の不備とPyTorchメモリ管理機構との相互作用による実質的なメモリリークであることが明らかになった。プロファイリング結果では断片化は0.32GB程度の増加に留まっているが、実際のメモリ使用量は3GB以上増加しており、この乖離が問題の本質を示している。

既存のバケツ化実装は技術的には適切に設計されているが、実際の問題解決においては限定的な効果しか発揮していない。むしろ、テンソル管理の厳格化とBERTモデル管理の改善が、より大きな効果を発揮する可能性が高い。

提案する解決策は全て技術的に実装可能であり、段階的な導入により実環境のメモリ問題を大幅に改善できると期待される。特に、テンソルライフサイクル管理とBERTモデル管理の改善を優先的に実装することで、実環境における300MB余裕という危険な状況を解消し、安定したサービス運用を実現できる。

ただし、根本的な解決のためには、音声合成APIサーバーのアーキテクチャレベルでの見直しも必要である。モデルの動的ロード・アンロード戦略、推論要求のバッチ処理機構、メモリ使用量ベースの負荷制御など、包括的なアプローチにより、長期的に安定したサービス運用を実現することが重要である。