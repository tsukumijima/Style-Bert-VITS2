import re
import sys
import unicodedata
from datetime import datetime

from num2words import num2words

from style_bert_vits2.nlp.japanese.katakana_map import KATAKANA_MAP
from style_bert_vits2.nlp.japanese.romkan import to_katakana
from style_bert_vits2.nlp.symbols import PUNCTUATIONS


# è¨˜å·é¡ã®æ­£è¦åŒ–ãƒãƒƒãƒ—
__SYMBOL_REPLACE_MAP = {
    "ï¼š": ",",
    "ï¼›": ",",
    "ï¼Œ": ",",
    "ã€‚": ".",
    "ï¼": "!",
    "ï¼Ÿ": "?",
    "\n": ".",
    "ï¼": ".",
    "â€¦": "...",
    "Â·Â·Â·": "...",
    "ãƒ»ãƒ»ãƒ»": "...",
    "/": ".",
    "ï¼": ".",
    "Â·": ",",
    "ãƒ»": ",",
    "ã€": ",",
    "$": ".",
    "â€œ": "'",
    "â€": "'",
    '"': "'",
    "â€˜": "'",
    "â€™": "'",
    "ï¼ˆ": "'",
    "ï¼‰": "'",
    "(": "'",
    ")": "'",
    "ã€Š": "'",
    "ã€‹": "'",
    "ã€": "'",
    "ã€‘": "'",
    "[": "'",
    "]": "'",
    # NFKC æ­£è¦åŒ–å¾Œã®ãƒã‚¤ãƒ•ãƒ³ãƒ»ãƒ€ãƒƒã‚·ãƒ¥ã®å¤‰ç¨®ã‚’å…¨ã¦é€šå¸¸åŠè§’ãƒã‚¤ãƒ•ãƒ³ - \u002d ã«å¤‰æ›
    "\u02d7": "\u002d",  # Ë—, Modifier Letter Minus Sign
    "\u2010": "\u002d",  # â€, Hyphen,
    # "\u2011": "\u002d",  # â€‘, Non-Breaking Hyphen, NFKC ã«ã‚ˆã‚Š \u2010 ã«å¤‰æ›ã•ã‚Œã‚‹
    "\u2012": "\u002d",  # â€’, Figure Dash
    "\u2013": "\u002d",  # â€“, En Dash
    "\u2014": "\u002d",  # â€”, Em Dash
    "\u2015": "\u002d",  # â€•, Horizontal Bar
    "\u2043": "\u002d",  # âƒ, Hyphen Bullet
    "\u2212": "\u002d",  # âˆ’, Minus Sign
    "\u23af": "\u002d",  # â¯, Horizontal Line Extension
    "\u23e4": "\u002d",  # â¤, Straightness
    "\u2500": "\u002d",  # â”€, Box Drawings Light Horizontal
    "\u2501": "\u002d",  # â”, Box Drawings Heavy Horizontal
    "\u2e3a": "\u002d",  # â¸º, Two-Em Dash
    "\u2e3b": "\u002d",  # â¸», Three-Em Dash
    # "ï½": "-",  # ã“ã‚Œã¯é•·éŸ³è¨˜å·ã€Œãƒ¼ã€ã¨ã—ã¦æ‰±ã†ã‚ˆã†å¤‰æ›´
    # "~": "-",  # ã“ã‚Œã‚‚é•·éŸ³è¨˜å·ã€Œãƒ¼ã€ã¨ã—ã¦æ‰±ã†ã‚ˆã†å¤‰æ›´
    "ã€Œ": "'",
    "ã€": "'",
}
# è¨˜å·é¡ã®æ­£è¦åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³
__SYMBOL_REPLACE_PATTERN = re.compile(
    "|".join(re.escape(p) for p in __SYMBOL_REPLACE_MAP)
)

# è¨˜å·ãªã©ã®èª­ã¿æ­£è¦åŒ–ãƒãƒƒãƒ—
__SYMBOL_YOMI_MAP = {
    # ç®—è¡“æ¼”ç®—å­
    "+": "ãƒ—ãƒ©ã‚¹",
    "ï¼‹": "ãƒ—ãƒ©ã‚¹",
    "â•": "ãƒ—ãƒ©ã‚¹",
    "â–": "ãƒã‚¤ãƒŠã‚¹",  # çµµæ–‡å­—ä»¥å¤–ã®ãƒã‚¤ãƒ•ãƒ³ã¯ä¼¸ã°ã™æ£’ã¨åŒºåˆ¥ãŒã¤ã‹ãªã„ã®ã§è¨˜è¿°ã—ã¦ã„ãªã„
    "Ã—": "æ›ã‘ã‚‹",
    "âœ–": "æ›ã‘ã‚‹",
    "â¨¯": "æ›ã‘ã‚‹",
    "Ã·": "å‰²ã‚‹",
    "â—": "å‰²ã‚‹",
    # ç­‰å·ãƒ»ä¸ç­‰å·
    "=": "ã‚¤ã‚³ãƒ¼ãƒ«",
    "ï¼": "ã‚¤ã‚³ãƒ¼ãƒ«",
    "â‰ ": "ãƒãƒƒãƒˆã‚¤ã‚³ãƒ¼ãƒ«",
    "â‰’": "ãƒ‹ã‚¢ãƒªãƒ¼ã‚¤ã‚³ãƒ¼ãƒ«",
    "â‰ˆ": "ãƒ‹ã‚¢ãƒªãƒ¼ã‚¤ã‚³ãƒ¼ãƒ«",
    "â‰…": "åˆåŒ",
    "â‰¡": "åˆåŒ",
    "â‰¢": "åˆåŒã§ãªã„",
    # æ¯”è¼ƒæ¼”ç®—å­
    "<": "æœªæº€",
    "ï¼œ": "æœªæº€",
    ">": "ã‚ˆã‚Šå¤§ãã„",
    "ï¼": "ã‚ˆã‚Šå¤§ãã„",
    "â‰¤": "ä»¥ä¸‹",
    "â‰¦": "ä»¥ä¸‹",
    "â‰¥": "ä»¥ä¸Š",
    "â‰§": "ä»¥ä¸Š",
    # å˜ä½ãƒ»æ•°å€¤è¨˜å·
    "%": "ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆ",
    "ï¼…": "ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆ",
    "Ùª": "ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆ",
    "ï¹ª": "ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆ",
    "â€°": "ãƒ‘ãƒ¼ãƒŸãƒ«",
    "â€±": "ãƒ‘ãƒ¼ãƒŸãƒªã‚¢ãƒ‰",
    "â€²": "ãƒ—ãƒ©ã‚¤ãƒ ",
    "â€³": "ãƒ€ãƒ–ãƒ«ãƒ—ãƒ©ã‚¤ãƒ ",
    "â€´": "ãƒˆãƒªãƒ—ãƒ«ãƒ—ãƒ©ã‚¤ãƒ ",
    "Â°": "åº¦",
    "â„ƒ": "åº¦",
    "â„‰": "åº¦",
    "Â±": "ãƒ—ãƒ©ã‚¹ãƒã‚¤ãƒŠã‚¹",
    "âˆ“": "ãƒã‚¤ãƒŠã‚¹ãƒ—ãƒ©ã‚¹",
    "â„–": "ãƒŠãƒ³ãƒãƒ¼",
    "â„¡": "ãƒ†ãƒ¬ãƒ•ã‚©ãƒ³",
    "â„ ": "ã‚¨ã‚¹ã‚¨ãƒ ",
    "â„¢": "ãƒ†ã‚£ãƒ¼ã‚¨ãƒ ",
    "Â©": "ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ãƒˆ",
    "Â®": "ã‚¢ãƒ¼ãƒ«ãƒãƒ¼ã‚¯",
    "ğŸ’²": "ãƒ‰ãƒ«",
    # ä¸€èˆ¬è¨˜å·
    "@": "ã‚¢ãƒƒãƒˆãƒãƒ¼ã‚¯",
    "ï¼ ": "ã‚¢ãƒƒãƒˆãƒãƒ¼ã‚¯",
    "#": "ãƒãƒƒã‚·ãƒ¥",
    "ï¼ƒ": "ãƒãƒƒã‚·ãƒ¥",
    "#ï¸âƒ£": "ãƒãƒƒã‚·ãƒ¥",
    "&": "ã‚¢ãƒ³ãƒ‰",
    "ï¼†": "ã‚¢ãƒ³ãƒ‰",
    "*": "ã‚¢ã‚¹ã‚¿ãƒªã‚¹ã‚¯",
    "ï¼Š": "ã‚¢ã‚¹ã‚¿ãƒªã‚¹ã‚¯",
    "â€ ": "ãƒ€ã‚¬ãƒ¼",
    "â€¡": "ãƒ€ãƒ–ãƒ«ãƒ€ã‚¬ãƒ¼",
    "Â§": "ã‚»ã‚¯ã‚·ãƒ§ãƒ³",
    "Â¶": "ãƒ‘ãƒ©ã‚°ãƒ©ãƒ•",
    # éŸ³æ¥½è¨˜å·
    "â™¯": "ã‚·ãƒ£ãƒ¼ãƒ—",
    "â™­": "ãƒ•ãƒ©ãƒƒãƒˆ",
    "â™®": "ãƒŠãƒãƒ¥ãƒ©ãƒ«",
    # "â™©": "éŸ³ç¬¦",
    # "â™ª": "éŸ³ç¬¦",
    # "â™«": "éŸ³ç¬¦",
    # "â™¬": "éŸ³ç¬¦",
    # æ•°å­¦è¨˜å·
    "âˆ§": "ã‹ã¤",
    "âˆ¨": "ã¾ãŸã¯",
    "Â¬": "ãƒãƒƒãƒˆ",
    "âŠ•": "æ’ä»–çš„è«–ç†å’Œ",
    "âŠ—": "ãƒ†ãƒ³ã‚½ãƒ«ç©",
    "âˆš": "ãƒ«ãƒ¼ãƒˆ",
    "âˆ›": "ç«‹æ–¹æ ¹",
    "âˆœ": "å››ä¹—æ ¹",
    "âˆ": "ç„¡é™å¤§",
    "â™¾ï¸": "ç„¡é™å¤§",
    "Ï€": "ãƒ‘ã‚¤",
    "âˆ‘": "ã‚·ã‚°ãƒ",
    "âˆ": "ãƒ‘ã‚¤ç©åˆ†",
    "âˆ«": "ã‚¤ãƒ³ãƒ†ã‚°ãƒ©ãƒ«",
    "âˆ¬": "äºŒé‡ç©åˆ†",
    "âˆ­": "ä¸‰é‡ç©åˆ†",
    "âˆ®": "å‘¨å›ç©åˆ†",
    "âˆ¯": "é¢ç©åˆ†",
    "âˆ°": "ä½“ç©åˆ†",
    "âˆ‚": "ãƒ‘ãƒ¼ã‚·ãƒ£ãƒ«",
    "âˆ‡": "ãƒŠãƒ–ãƒ©",
    "âˆ": "æ¯”ä¾‹",
    # é›†åˆè¨˜å·
    "âˆˆ": "å±ã™ã‚‹",
    "âˆ‰": "å±ã•ãªã„",
    "âˆ‹": "å«ã‚€",
    "âˆŒ": "å«ã¾ãªã„",
    "âˆª": "å’Œé›†åˆ",
    "âˆ©": "å…±é€šéƒ¨åˆ†",
    "âŠ‚": "éƒ¨åˆ†é›†åˆ",
    "âŠƒ": "ä¸Šä½é›†åˆ",
    "âŠ„": "éƒ¨åˆ†é›†åˆã§ãªã„",
    "âŠ…": "ä¸Šä½é›†åˆã§ãªã„",
    "âŠ†": "éƒ¨åˆ†é›†åˆã¾ãŸã¯ç­‰ã—ã„",
    "âŠ‡": "ä¸Šä½é›†åˆã¾ãŸã¯ç­‰ã—ã„",
    "âˆ…": "ç©ºé›†åˆ",
    "âˆ–": "å·®é›†åˆ",
    "âˆ†": "å¯¾ç§°å·®",
    # å¹¾ä½•è¨˜å·
    "âˆ¥": "å¹³è¡Œ",
    "âŠ¥": "å‚ç›´",
    "âˆ ": "è§’",
    "âˆŸ": "ç›´è§’",
    "âˆ¡": "æ¸¬å®šè§’",
    "âˆ¢": "çƒé¢è§’",
}
# è¨˜å·é¡ã®èª­ã¿æ­£è¦åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³
__SYMBOL_YOMI_PATTERN = re.compile("|".join(re.escape(p) for p in __SYMBOL_YOMI_MAP))

# å˜ä½ã®æ­£è¦åŒ–ãƒãƒƒãƒ—
# å˜ä½ã¯ OpenJTalk å´ã§ã‚‚å¤‰æ›ã—ã¦ãã‚Œã‚‹ã®ã§ã€å˜ä½ãŒ1æ–‡å­—ã§èª­ã¿é–“é•ã„ãŒç™ºç”Ÿã—ã‚„ã™ã„ L, m, g, B ã¨ãã®é–¢é€£å˜ä½ã®ã¿å¤‰æ›ã™ã‚‹
__UNIT_MAP = {
    "kL": "ã‚­ãƒ­ãƒªãƒƒãƒˆãƒ«",
    "L": "ãƒªãƒƒãƒˆãƒ«",
    "dL": "ãƒ‡ã‚·ãƒªãƒƒãƒˆãƒ«",
    "mL": "ãƒŸãƒªãƒªãƒƒãƒˆãƒ«",
    "km": "ã‚­ãƒ­ãƒ¡ãƒ¼ãƒˆãƒ«",
    "m": "ãƒ¡ãƒ¼ãƒˆãƒ«",
    "cm": "ã‚»ãƒ³ãƒãƒ¡ãƒ¼ãƒˆãƒ«",
    "mm": "ãƒŸãƒªãƒ¡ãƒ¼ãƒˆãƒ«",
    "kg": "ã‚­ãƒ­ã‚°ãƒ©ãƒ ",
    "g": "ã‚°ãƒ©ãƒ ",
    "mg": "ãƒŸãƒªã‚°ãƒ©ãƒ ",
    "PB": "ãƒšã‚¿ãƒã‚¤ãƒˆ",
    "PiB": "ãƒšãƒ“ãƒã‚¤ãƒˆ",
    "TB": "ãƒ†ãƒ©ãƒã‚¤ãƒˆ",
    "TiB": "ãƒ†ãƒ“ãƒã‚¤ãƒˆ",
    "GB": "ã‚®ã‚¬ãƒã‚¤ãƒˆ",
    "GiB": "ã‚®ãƒ“ãƒã‚¤ãƒˆ",
    "MB": "ãƒ¡ã‚¬ãƒã‚¤ãƒˆ",
    "MiB": "ãƒ¡ãƒ“ãƒã‚¤ãƒˆ",
    "KB": "ã‚­ãƒ­ãƒã‚¤ãƒˆ",
    "kB": "ã‚­ãƒ­ãƒã‚¤ãƒˆ",
    "KiB": "ã‚­ãƒ“ãƒã‚¤ãƒˆ",
    "B": "ãƒã‚¤ãƒˆ",
}
# å˜ä½ã®æ­£è¦åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³
__UNIT_PATTERN = re.compile(
    r"([0-9.]*[0-9])\s*((k|d|m)?L|(k|c|m)?m|(k|m)?g|PB|PiB|TB|TiB|GB|GiB|MB|MiB|KB|kB|KiB|B)(?=[^a-zA-Z]|$)"
)

# å¥èª­ç‚¹ç­‰ã®æ­£è¦åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³
__PUNCTUATION_CLEANUP_PATTERN = re.compile(
    # â†“ ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—
    r"[^\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF\u3400-\u4DBF\u3005"
    # â†“ åŠè§’æ•°å­—
    + r"\u0030-\u0039"
    # â†“ åŠè§’ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆï¼ˆå¤§æ–‡å­—ã¨å°æ–‡å­—ï¼‰
    + r"\u0041-\u005A\u0061-\u007A"
    # â†“ å…¨è§’ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆï¼ˆå¤§æ–‡å­—ã¨å°æ–‡å­—ï¼‰
    + r"\uFF21-\uFF3A\uFF41-\uFF5A"
    # â†“ ã‚®ãƒªã‚·ãƒ£æ–‡å­—
    + r"\u0370-\u03FF\u1F00-\u1FFF"
    # â†“ "!", "?", "â€¦", ",", ".", "'", "-", ä½†ã—`â€¦`ã¯ã™ã§ã«`...`ã«å¤‰æ›ã•ã‚Œã¦ã„ã‚‹
    + "".join(PUNCTUATIONS) + r"]+",  # fmt: skip
)

# æ•°å­—ãƒ»é€šè²¨è¨˜å·ã®æ­£è¦åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³
__CURRENCY_MAP = {
    "$": "ãƒ‰ãƒ«",
    "Â¥": "å††",
    "â‚¬": "ãƒ¦ãƒ¼ãƒ­",
    "Â£": "ãƒãƒ³ãƒ‰",
    "â‚©": "ã‚¦ã‚©ãƒ³",
    "â‚¹": "ãƒ«ãƒ”ãƒ¼",  # ã‚¤ãƒ³ãƒ‰ãƒ»ãƒ«ãƒ”ãƒ¼
    "â‚½": "ãƒ«ãƒ¼ãƒ–ãƒ«",
    "â‚º": "ãƒªãƒ©",  # ãƒˆãƒ«ã‚³ãƒ»ãƒªãƒ©
    "à¸¿": "ãƒãƒ¼ãƒ„",
    "â‚±": "ãƒšã‚½",  # ãƒ•ã‚£ãƒªãƒ”ãƒ³ãƒ»ãƒšã‚½
    "â‚´": "ãƒ•ãƒªãƒ´ãƒ‹ãƒ£",
    "â‚«": "ãƒ‰ãƒ³",
    "â‚ª": "ã‚·ã‚§ã‚±ãƒ«",  # ã‚¤ã‚¹ãƒ©ã‚¨ãƒ«ãƒ»æ–°ã‚·ã‚§ã‚±ãƒ«
    "â‚¦": "ãƒŠã‚¤ãƒ©",
    "â‚¡": "ã‚³ãƒ­ãƒ³",  # ã‚³ã‚¹ã‚¿ãƒªã‚«ãƒ»ã‚³ãƒ­ãƒ³
    "â‚¿": "ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³",
    "ï·¼": "ãƒªãƒ¤ãƒ«",  # ã‚µã‚¦ã‚¸ã‚¢ãƒ©ãƒ“ã‚¢ãƒ»ãƒªãƒ¤ãƒ«
    "â‚ ": "ECU",  # European Currency Unit (å»ƒæ­¢)
    "â‚¢": "ã‚¯ãƒ«ã‚¶ãƒ¼ãƒ‰",  # ãƒ–ãƒ©ã‚¸ãƒ«ãƒ»ã‚¯ãƒ«ã‚¶ãƒ¼ãƒ‰ (å»ƒæ­¢)
    "â‚£": "ãƒ•ãƒ©ãƒ³ã‚¹ãƒ•ãƒ©ãƒ³",  # ãƒ•ãƒ©ãƒ³ã‚¹ãƒ»ãƒ•ãƒ©ãƒ³ (å»ƒæ­¢)
    "â‚¤": "ãƒªãƒ©",  # ã‚¤ã‚¿ãƒªã‚¢ãƒ»ãƒªãƒ© (å»ƒæ­¢)
    "â‚¥": "ãƒŸãƒ«",  # ã‚¢ãƒ¡ãƒªã‚«ãƒ»ãƒŸãƒ« (å»ƒæ­¢)
    "â‚§": "ãƒšã‚»ã‚¿",  # ã‚¹ãƒšã‚¤ãƒ³ãƒ»ãƒšã‚»ã‚¿ (å»ƒæ­¢)
    "â‚¨": "ãƒ«ãƒ”ãƒ¼",  # ãƒ‘ã‚­ã‚¹ã‚¿ãƒ³ãƒ»ãƒ«ãƒ”ãƒ¼
    "â‚­": "ã‚­ãƒ¼ãƒ—",  # ãƒ©ã‚ªã‚¹ãƒ»ã‚­ãƒ¼ãƒ—
    "â‚®": "ãƒˆã‚¥ã‚°ãƒ«ã‚°",  # ãƒ¢ãƒ³ã‚´ãƒ«ãƒ»ãƒˆã‚¥ã‚°ãƒ«ã‚°
    "â‚¯": "ãƒ‰ãƒ©ã‚¯ãƒ",  # ã‚®ãƒªã‚·ãƒ£ãƒ»ãƒ‰ãƒ©ã‚¯ãƒ (å»ƒæ­¢)
    "â‚°": "ãƒ‰ã‚¤ãƒ„ãƒšãƒ‹ãƒ’",  # ãƒ‰ã‚¤ãƒ„ãƒ»ãƒšãƒ‹ãƒ’ (å»ƒæ­¢)
    "â‚²": "ã‚°ã‚¢ãƒ©ãƒ‹ãƒ¼",  # ãƒ‘ãƒ©ã‚°ã‚¢ã‚¤ãƒ»ã‚°ã‚¢ãƒ©ãƒ‹ãƒ¼
    "â‚³": "ã‚¢ã‚¦ã‚¹ãƒˆãƒ©ãƒ¼ãƒ«",  # ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³ãƒ»ã‚¢ã‚¦ã‚¹ãƒˆãƒ©ãƒ¼ãƒ« (å»ƒæ­¢)
    "â‚µ": "ã‚»ãƒ‡ã‚£",  # ã‚¬ãƒ¼ãƒŠãƒ»ã‚»ãƒ‡ã‚£
    "â‚¶": "ãƒªãƒ´ãƒ«ãƒˆã‚¥ãƒ¼ãƒ«ãƒŒãƒ¯",  # ãƒ•ãƒ©ãƒ³ã‚¹ãƒ»ãƒªãƒ´ãƒ«ãƒˆã‚¥ãƒ¼ãƒ«ãƒŒãƒ¯ (å»ƒæ­¢)
    "â‚·": "ã‚¹ãƒšãƒ«ãƒªãƒ³ã‚°",  # ãƒãƒ«ã‚¿ãƒ»ã‚¹ãƒšãƒ«ãƒªãƒ³ã‚° (å»ƒæ­¢)
    "â‚¸": "ãƒ†ãƒ³ã‚²",  # ã‚«ã‚¶ãƒ•ã‚¹ã‚¿ãƒ³ãƒ»ãƒ†ãƒ³ã‚²
    "â‚»": "ãƒãƒŠãƒˆ",  # ãƒˆãƒ«ã‚¯ãƒ¡ãƒ‹ã‚¹ã‚¿ãƒ³ãƒ»ãƒãƒŠãƒˆ
    "â‚¼": "ã‚¢ã‚¼ãƒ«ãƒã‚¤ã‚¸ãƒ£ãƒ³ãƒãƒŠãƒˆ",
    "â‚¾": "ãƒ©ãƒª",  # ã‚¸ãƒ§ãƒ¼ã‚¸ã‚¢ãƒ»ãƒ©ãƒª
}
__CURRENCY_PATTERN = re.compile(
    r"([$Â¥â‚¬Â£â‚©â‚¹â‚½â‚ºà¸¿â‚±â‚´â‚«â‚ªâ‚¦â‚¡â‚¿ï·¼â‚ â‚¢â‚£â‚¤â‚¥â‚§â‚¨â‚­â‚®â‚¯â‚°â‚²â‚³â‚µâ‚¶â‚·â‚¸â‚»â‚¼â‚¾])([0-9.]*[0-9])"
)
__NUMBER_PATTERN = re.compile(r"[0-9]+(\.[0-9]+)?")
__NUMBER_WITH_SEPARATOR_PATTERN = re.compile("[0-9]{1,3}(,[0-9]{3})+")

# __replace_symbols() ã§ä½¿ã†æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
__NUMBER_RANGE_PATTERN = re.compile(r"(\d+)\s*[ã€œ~ï½]\s*(\d+)")
__NUMBER_MATH_PATTERN = re.compile(r"(\d+)\s*([+\-Ã—Ã·])\s*(\d+)\s*=\s*(\d+)")
__DATE_EXPAND_PATTERN = re.compile(r"\d{2}[-/]\d{1,2}[-/]\d{1,2}")
__DATE_PATTERN = re.compile(
    r"\d{4}[-/]\d{1,2}[-/]\d{1,2}|\d{2}[-/]\d{1,2}[-/]\d{1,2}|\d{1,2}/\d{1,2}"
)
__FRACTION_PATTERN = re.compile(r"(\d+)[/ï¼](\d+)")
__ASPECT_PATTERN = re.compile(r"(\d+)[:ï¼š](\d+)")
__EXPONENT_PATTERN = re.compile(r"(\d+(?:\.\d+)?)[eE]([-+]?\d+)")

# __convert_english_to_katakana() ã§ä½¿ã†æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
__ENGLISH_WORD_PATTERN = re.compile(r"[a-zA-Z0-9]")
__ENGLISH_WORD_WITH_NUMBER_PATTERN = re.compile(r"^([a-zA-Z]+)([0-9]{1,2})$")
__ALPHABET_PATTERN = re.compile(r"[a-zA-Z]")


def normalize_text(text: str) -> str:
    """
    æ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–ã™ã‚‹ã€‚
    çµæœã¯ã€ã¡ã‚‡ã†ã©æ¬¡ã®æ–‡å­—ã®ã¿ã‹ã‚‰ãªã‚‹ï¼š
    - ã²ã‚‰ãŒãª
    - ã‚«ã‚¿ã‚«ãƒŠï¼ˆå…¨è§’é•·éŸ³è¨˜å·ã€Œãƒ¼ã€ãŒå…¥ã‚‹ï¼ï¼‰
    - æ¼¢å­—
    - åŠè§’æ•°å­—
    - åŠè§’ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆï¼ˆå¤§æ–‡å­—ã¨å°æ–‡å­—ï¼‰
    - ã‚®ãƒªã‚·ãƒ£æ–‡å­—
    - `.` ï¼ˆå¥ç‚¹`ã€‚`ã‚„`â€¦`ã®ä¸€éƒ¨ã‚„æ”¹è¡Œç­‰ï¼‰
    - `,` ï¼ˆèª­ç‚¹`ã€`ã‚„`:`ç­‰ï¼‰
    - `?` ï¼ˆç–‘å•ç¬¦`ï¼Ÿ`ï¼‰
    - `!` ï¼ˆæ„Ÿå˜†ç¬¦`ï¼`ï¼‰
    - `'` ï¼ˆ`ã€Œ`ã‚„`ã€`ç­‰ï¼‰
    - `-` ï¼ˆ`â€•`ï¼ˆãƒ€ãƒƒã‚·ãƒ¥ã€é•·éŸ³è¨˜å·ã§ã¯ãªã„ï¼‰ã‚„`-`ç­‰ï¼‰

    æ³¨æ„ç‚¹:
    - ä¸‰ç‚¹ãƒªãƒ¼ãƒ€ãƒ¼`â€¦`ã¯`...`ã«å¤‰æ›ã•ã‚Œã‚‹ï¼ˆ`ãªã‚‹ã»ã©â€¦ã€‚` â†’ `ãªã‚‹ã»ã©....`ï¼‰
    - èª­ç‚¹ã‚„ç–‘å•ç¬¦ç­‰ã®ä½ç½®ãƒ»å€‹æ•°ç­‰ã¯ä¿æŒã•ã‚Œã‚‹ï¼ˆ`??ã‚ã€ã€ï¼ï¼ï¼` â†’ `??ã‚,,!!!`ï¼‰

    Args:
        text (str): æ­£è¦åŒ–ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        str: æ­£è¦åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """

    # ä¸€ç•ªå…ˆã«è¨˜å·ã‚’å¤‰æ›
    # æœ€åˆã§ãªã„ã¨ â„ƒ ãŒ unicodedata.normalize() ã§åˆ†å‰²ã•ã‚Œã¦ã—ã¾ã†
    res = __replace_symbols(text)

    # è‡ªç„¶ãªæ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ã®ãŸã‚ã«ã€å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã¯å¥ç‚¹ã«å¤‰æ›
    # åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ãŒå…¥ã‚‹ç®‡æ‰€ã§æ­¢ã‚ã¦èª­ã‚€ã‹ã¯ã‚±ãƒ¼ã‚¹ãƒã‚¤ã‚±ãƒ¼ã‚¹ãªãŸã‚ã€å¤‰æ›ã¯è¡Œã‚ãªã„
    # Unicode æ­£è¦åŒ–ã§ã‚¹ãƒšãƒ¼ã‚¹ãŒå…¨ã¦åŠè§’ã«å¤‰æ›ã•ã‚Œã‚‹å‰ã«å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚‹
    res = res.replace("\u3000", "ã€‚")

    res = unicodedata.normalize("NFKC", res)  # ã“ã“ã§ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã¯åŠè§’ã«ãªã‚‹

    res = __convert_english_to_katakana(res)  # è‹±å˜èªã‚’ã‚«ã‚¿ã‚«ãƒŠã«å¤‰æ›

    res = __convert_numbers_to_words(res)  # ã€Œ100å††ã€â†’ã€Œç™¾å††ã€ç­‰
    # ã€Œï½ã€ã¨ã€Œã€œã€ã¨ã€Œ~ã€ã‚‚é•·éŸ³è¨˜å·ã¨ã—ã¦æ‰±ã†
    res = res.replace("~", "ãƒ¼")
    res = res.replace("ï½", "ãƒ¼")
    res = res.replace("ã€œ", "ãƒ¼")

    res = replace_punctuation(res)  # å¥èª­ç‚¹ç­‰æ­£è¦åŒ–ã€èª­ã‚ãªã„æ–‡å­—ã‚’å‰Šé™¤

    # çµåˆæ–‡å­—ã®æ¿ç‚¹ãƒ»åŠæ¿ç‚¹ã‚’å‰Šé™¤
    # é€šå¸¸ã®ã€Œã°ã€ç­‰ã¯ãã®ã¾ã¾ã®ã“ã•ã‚Œã‚‹ã€ã€Œã‚ã‚›ã€ã¯ä¸Šã§ã€Œã‚ã‚™ã€ã«ãªã‚Šã“ã“ã§ã€Œã‚ã€ã«ãªã‚‹
    res = res.replace("\u3099", "")  # çµåˆæ–‡å­—ã®æ¿ç‚¹ã‚’å‰Šé™¤ã€ã‚‹ã‚™ â†’ ã‚‹
    res = res.replace("\u309A", "")  # çµåˆæ–‡å­—ã®åŠæ¿ç‚¹ã‚’å‰Šé™¤ã€ãªã‚š â†’ ãª
    return res


def __replace_symbols(text: str) -> str:
    """
    è¨˜å·é¡ã®èª­ã¿ã‚’é©åˆ‡ã«å¤‰æ›ã™ã‚‹ã€‚

    Args:
        text (str): æ­£è¦åŒ–ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        str: æ­£è¦åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """

    # æ•°å­—ã¨æ•°å­—ã«æŒŸã¾ã‚ŒãŸã€Œã€œã€ã‚’ã€Œã‹ã‚‰ã€ã«ç½®æ›
    text = __NUMBER_RANGE_PATTERN.sub(lambda m: f"{m.group(1)}ã‹ã‚‰{m.group(2)}", text)

    # æ•°å¼ã®èª­ã¿æ–¹ã‚’æ”¹å–„
    text = __NUMBER_MATH_PATTERN.sub(
        lambda m: f"{m.group(1)}{__SYMBOL_YOMI_MAP.get(m.group(2), m.group(2))}{m.group(3)}ã‚¤ã‚³ãƒ¼ãƒ«{m.group(4)}",
        text,
    )

    def date_to_words(match: re.Match[str]) -> str:
        date_str = match.group(0)
        try:
            # 2æ¡ã®å¹´ã‚’4æ¡ã«æ‹¡å¼µã™ã‚‹å‡¦ç† (Y/m/d or Y-m-d ã®æ™‚ã®ã¿)
            if __DATE_EXPAND_PATTERN.match(date_str):
                # ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã¾ãŸã¯ãƒã‚¤ãƒ•ãƒ³ã§åˆ†å‰²ã—ã¦å¹´éƒ¨åˆ†ã‚’å–å¾—
                year_str = (
                    date_str.split("/")[0]
                    if "/" in date_str
                    else date_str.split("-")[0]
                )
                if len(year_str) == 2:
                    # 50 ä»¥é™ã¯ 1900 å¹´ä»£ã€49 ä»¥å‰ã¯ 2000 å¹´ä»£ã¨ã—ã¦æ‰±ã†
                    # 98/04/11 â†’ 1998/04/11 / 36-01-01 â†’ 2036-01-01
                    year_prefix = "19" if int(year_str) >= 50 else "20"
                    date_str = year_prefix + date_str

            # Y/m/d, Y-m-d, m/d ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™
            for fmt in ["%Y/%m/%d", "%Y-%m-%d", "%m/%d"]:
                try:
                    date = datetime.strptime(date_str, fmt)
                    if fmt == "%m/%d":
                        return f"{date.month}æœˆ{date.day}æ—¥"
                    return f"{date.year}å¹´{date.month}æœˆ{date.day}æ—¥"
                except ValueError:
                    continue
            # ã©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚‚ä¸€è‡´ã—ãªã„å ´åˆã¯å…ƒã®æ–‡å­—åˆ—ã‚’è¿”ã™
            return date_str
        except Exception:
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯å…ƒã®æ–‡å­—åˆ—ã‚’è¿”ã™
            return date_str

    # æ—¥ä»˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¤‰æ›
    text = __DATE_PATTERN.sub(date_to_words, text)

    # åˆ†æ•°ã®å‡¦ç†
    text = __FRACTION_PATTERN.sub(
        lambda m: f'{num2words(m.group(2), lang="ja")}åˆ†ã®{num2words(m.group(1), lang="ja")}',
        text,
    )

    # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã®å‡¦ç†
    text = __ASPECT_PATTERN.sub(
        lambda m: f'{num2words(m.group(1), lang="ja")}ãŸã„{num2words(m.group(2), lang="ja")}',
        text,
    )

    # æŒ‡æ•°è¡¨è¨˜ã®å‡¦ç†
    text = __EXPONENT_PATTERN.sub(
        lambda m: f'{num2words(float(m.group(0)), lang="ja")}', text
    )

    # è¨˜å·é¡ã‚’è¾æ›¸ã§ç½®æ›
    text = __SYMBOL_YOMI_PATTERN.sub(lambda x: __SYMBOL_YOMI_MAP[x.group()], text)

    return text


def __convert_numbers_to_words(text: str) -> str:
    """
    è¨˜å·ã‚’æ—¥æœ¬èªã®æ–‡å­—è¡¨ç¾ã«å¤‰æ›ã™ã‚‹ã€‚
    ä»¥å‰ã¯æ•°å­—ã‚’æ¼¢æ•°å­—è¡¨ç¾ã«å¤‰æ›ã—ã¦ã„ãŸãŒã€pyopenjtalk å´ã®å¤‰æ›å‡¦ç†ã®æ–¹ãŒå„ªç§€ãªãŸã‚æ’¤å»ã—ãŸã€‚

    Args:
        text (str): å¤‰æ›ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        str: å¤‰æ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """

    res = __UNIT_PATTERN.sub(lambda m: m[1] + __UNIT_MAP.get(m[2], m[2]), text)
    res = __NUMBER_WITH_SEPARATOR_PATTERN.sub(lambda m: m[0].replace(",", ""), res)
    res = __CURRENCY_PATTERN.sub(lambda m: m[2] + __CURRENCY_MAP.get(m[1], m[1]), res)

    return res


def __convert_english_to_katakana(text: str) -> str:
    """
    ãƒ†ã‚­ã‚¹ãƒˆä¸­ã®è‹±å˜èªã‚’ã‚«ã‚¿ã‚«ãƒŠã«å¤‰æ›ã™ã‚‹ã€‚
    è¤‡åˆèªã‚„ç•¥èªã€è¨˜å·ã‚’å«ã‚€å˜èªãªã©ã€æ§˜ã€…ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œã™ã‚‹ã€‚
    ãŸã ã—ã€èª¤å¤‰æ›ã‚’é˜²ããŸã‚ã€ç¢ºå®Ÿã«å¤‰æ›ã§ãã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿ã‚’å‡¦ç†ã™ã‚‹ã€‚

    Args:
        text (str): å¤‰æ›ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        str: å¤‰æ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """

    def split_camel_case(word: str) -> list[str]:
        """
        CamelCase ã®å˜èªã‚’åˆ†å‰²ã™ã‚‹ã€‚
        å¤§æ–‡å­—ãŒé€£ç¶šã™ã‚‹å ´åˆã¯ãã‚Œã‚’ä¸€ã¤ã®éƒ¨åˆ†ã¨ã—ã¦æ‰±ã†ã€‚

        Args:
            word (str): åˆ†å‰²ã™ã‚‹å˜èª

        Returns:
            list[str]: åˆ†å‰²ã•ã‚ŒãŸéƒ¨åˆ†æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆ
        """

        parts = []
        current = word[0]
        prev_is_upper = word[0].isupper()

        for char in word[1:]:
            is_upper = char.isupper()

            # å°æ–‡å­—ã‹ã‚‰å¤§æ–‡å­—ã¸ã®å¤‰åŒ–ã€ã¾ãŸã¯å¤§æ–‡å­—ã‹ã‚‰å°æ–‡å­—ã¸ã®å¤‰åŒ–ã‚’æ¤œå‡º
            if (is_upper and not prev_is_upper) or (
                not is_upper and prev_is_upper and len(current) > 1
            ):
                parts.append(current)
                current = char
            else:
                current += char

            prev_is_upper = is_upper

        if current:
            parts.append(current)

        return parts

    def process_english_word(word: str, enable_romaji: bool = False) -> str:
        """
        è‹±å˜èªã‚’ã‚«ã‚¿ã‚«ãƒŠã«å¤‰æ›ã™ã‚‹ã€‚ç¢ºå®Ÿã«å¤‰æ›ã§ãã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿ã‚’å‡¦ç†ã—ã€
        ä¸ç¢ºå®Ÿãªå ´åˆã¯å…ƒã®å˜èªã‚’ãã®ã¾ã¾è¿”ã™ (pyopenjtalk å´ã§ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆèª­ã¿ã•ã‚Œã‚‹)ã€‚

        Args:
            word (str): å¤‰æ›ã™ã‚‹è‹±å˜èª
            enable_romaji (bool): ãƒ­ãƒ¼ãƒå­—å¤‰æ›ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹ã©ã†ã‹
        Returns:
            str: ã‚«ã‚¿ã‚«ãƒŠã«å¤‰æ›ã•ã‚ŒãŸå˜èª
        """

        # è‹±å˜èªã®æœ«å°¾ã«2æ¡ä»¥ä¸‹ã®æ•°å­—ãŒã¤ãå ´åˆã®å‡¦ç†
        number_match = __ENGLISH_WORD_WITH_NUMBER_PATTERN.match(word)
        if number_match:
            base_word = number_match.group(1)
            number = number_match.group(2)
            # ã¾ãš base_word ã‚’ã‚«ã‚¿ã‚«ãƒŠã«å¤‰æ›ã§ãã‚‹ã‹ç¢ºèª
            base_katakana = KATAKANA_MAP.get(base_word.lower())
            if base_katakana:
                # æ•°å­—ã‚’è‹±èªè¡¨ç¾ã«å¤‰æ›ã—ã€ãã‚Œã‚’ã‚«ã‚¿ã‚«ãƒŠã«å¤‰æ›
                number_in_english = num2words(int(number), lang="en")
                number_katakana = process_english_word(number_in_english)
                if number_katakana:
                    return base_katakana + number_katakana

        # 1. å®Œå…¨ä¸€è‡´ã§ã®å¤‰æ›ã‚’è©¦ã¿ã‚‹ï¼ˆæœ€ã‚‚ä¿¡é ¼ã§ãã‚‹å¤‰æ›ï¼‰
        # 1.1 ã¾ãšå…ƒã®æ–‡å­—åˆ—ã§è©¦ã™ï¼ˆè¾æ›¸ã«å¤§æ–‡å­—ã§ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹é ­å­—èªã¯ã“ã“ã§å¤‰æ›ã•ã‚Œã‚‹ï¼‰
        katakana_word = KATAKANA_MAP.get(word)
        if katakana_word:
            return katakana_word
        # 1.2 å°æ–‡å­—ã«å¤‰æ›ã—ãŸä¸Šã§è©¦ã™
        katakana_word = KATAKANA_MAP.get(word.lower())
        if katakana_word:
            return katakana_word

        # 2. æœ«å°¾ã®ãƒ”ãƒªã‚ªãƒ‰ã‚’é™¤å»ã—ã¦å†è©¦è¡Œ
        if word.endswith("."):
            katakana_word = KATAKANA_MAP.get(word[:-1].lower())
            if katakana_word:
                return katakana_word

        # 3. æ‰€æœ‰æ ¼ã®å‡¦ç†ï¼ˆç¢ºå®Ÿãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        if word.lower().endswith(("'s", "â€™s")):
            base_word = word[:-2]
            katakana_word = KATAKANA_MAP.get(base_word.lower())
            if katakana_word:
                return katakana_word + "ã‚º"

        # 4. è¤‡æ•°å½¢ã®å‡¦ç†
        if word.endswith("s"):
            base_word = word[:-1]
            katakana_word = KATAKANA_MAP.get(base_word.lower())
            if katakana_word:
                return katakana_word + "ã‚º"

        # 5. è¨˜å·ã§åŒºåˆ‡ã‚‰ã‚ŒãŸè¤‡åˆèªã®å‡¦ç†ï¼ˆéƒ¨åˆ†çš„ãªå¤‰æ›ã‚’è¨±å¯ï¼‰
        for separator, join_word in [
            ("&", "ã‚¢ãƒ³ãƒ‰"),
            ("-", ""),
            (".", ""),
            ("+", "ãƒ—ãƒ©ã‚¹"),
        ]:
            if separator in word:
                # "." ã®å ´åˆã¯ã€å°æ•°ç‚¹ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
                if separator == ".":
                    parts = word.split(".")
                    # éš£æ¥ã™ã‚‹éƒ¨åˆ†ãŒä¸¡æ–¹æ•°å­—ã®å ´åˆã¯æ¬¡ã®ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã¸
                    should_skip = False
                    for i in range(len(parts) - 1):
                        if (
                            parts[i]
                            and parts[i][-1].isdigit()
                            and parts[i + 1]
                            and parts[i + 1][0].isdigit()
                        ):
                            should_skip = True
                            break
                    if should_skip:
                        continue

                sub_words = word.split(separator)
                katakana_sub_words = []

                for sub in sub_words:
                    # è¾æ›¸ã«ã‚ã‚‹å ´åˆã¯ã‚«ã‚¿ã‚«ãƒŠã«å¤‰æ›ã€ãªã„å ´åˆã¯å…ƒã®å˜èªã‚’ãã®ã¾ã¾ä½¿ç”¨
                    sub_katakana = KATAKANA_MAP.get(sub.lower(), sub)
                    katakana_sub_words.append(sub_katakana)

                return join_word.join(katakana_sub_words)

        # 6. ã®å‡¦ç†ã‚’è¡Œã†å‰ã«ã€å…ˆè¡Œã—ã¦å˜ä½ç³»ã®å¤‰æ›ã‚’çµ‚ã‚ã‚‰ã›ã¦ãŠã
        # ã•ã‚‚ãªã‘ã‚Œã°ã€ŒMiBã€ãŒåˆ†å‰²ã•ã‚Œã¦ã—ã¾ã†
        word = __UNIT_PATTERN.sub(lambda m: m[1] + __UNIT_MAP.get(m[2], m[2]), word)

        # 6. CamelCase ã®è¤‡åˆèªã‚’å‡¦ç†
        if any(c.isupper() for c in word[1:]):  # 2æ–‡å­—ç›®ä»¥é™ã«å¤§æ–‡å­—ãŒå«ã¾ã‚Œã‚‹
            parts = split_camel_case(word)
            result_parts = []

            for part in parts:
                # å¤§æ–‡å­—ã®ã¿ã§æ§‹æˆã•ã‚Œã‚‹éƒ¨åˆ†
                # è¾æ›¸ã«ãªã‘ã‚Œã°ãã®ã¾ã¾ã€pyopenjtalk ã§ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆèª­ã¿ã•ã‚Œã‚‹
                if all(c.isupper() for c in part):
                    result_parts.append(KATAKANA_MAP.get(part, part))
                else:
                    # ãã‚Œä»¥å¤–ã¯è¾æ›¸ã§å¤‰æ›ã‚’è©¦ã¿ã‚‹
                    converted = process_english_word(part)
                    result_parts.append(converted)

            # ã“ã“ã§ã¯æˆ»ã‚‰ãšã€å€¤ã®ä¸Šæ›¸ãã®ã¿ã«ã¨ã©ã‚ã‚‹
            word = "".join(result_parts)

        # 7. æ•°å­—ï¼ˆå°æ•°ç‚¹å«ã‚€ï¼‰ãŒå«ã¾ã‚Œã‚‹å ´åˆã€æ•°å­—éƒ¨åˆ†ã¨ãã‚Œä»¥å¤–ã®éƒ¨åˆ†ã«åˆ†å‰²ã—ã¦å‡¦ç†
        if any(c.isdigit() for c in word):

            # æ•°å­—ï¼ˆå°æ•°ç‚¹å«ã‚€ï¼‰ã¨ãã‚Œä»¥å¤–ã®éƒ¨åˆ†ã‚’åˆ†å‰²
            parts = []
            last_end = 0

            for match in __NUMBER_PATTERN.finditer(word):
                # æ•°å­—ã®å‰ã®éƒ¨åˆ†ã‚’å‡¦ç†
                if match.start() > last_end:
                    non_number = word[last_end : match.start()]
                    parts.append(process_english_word(non_number))

                # æ•°å­—éƒ¨åˆ†ã‚’ãã®ã¾ã¾è¿½åŠ 
                parts.append(match.group())
                last_end = match.end()

            # æœ€å¾Œã®éæ•°å­—éƒ¨åˆ†ã‚’å‡¦ç†
            if last_end < len(word):
                non_number = word[last_end:]
                parts.append(process_english_word(non_number))

            return "".join(parts)

        # 8. ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆãŒå«ã¾ã‚Œã‚‹å ´åˆã€ãƒ­ãƒ¼ãƒå­— -> ã‚«ã‚¿ã‚«ãƒŠå¤‰æ›ã‚’è©¦ã¿ã‚‹
        # 2æ–‡å­—ä»¥ä¸Šã®å ´åˆã®ã¿å¤‰æ›ã‚’è©¦ã¿ã‚‹ (I -> ã‚¤ ã®ã‚ˆã†ãª1æ–‡å­—å¤‰æ›ã‚’é˜²ã)
        if (
            len(word) >= 2
            and any(__ALPHABET_PATTERN.match(c) for c in word)
            and enable_romaji
        ):
            katakana = to_katakana(word)
            # å…¨æ–‡å­—ã‚’å®Œå…¨ã«ã‚«ã‚¿ã‚«ãƒŠã«å¤‰æ›ã§ããŸå ´åˆã®ã¿æ¡ç”¨
            if not any(__ALPHABET_PATTERN.match(c) for c in katakana):
                return katakana

        # ä¸Šè¨˜ä»¥å¤–ã¯å…ƒã®å˜èªã‚’è¿”ã™ (pyopenjtalk å´ã§ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆèª­ã¿ã•ã‚Œã‚‹)
        return word

    words = []
    current_word = ""
    prev_char = ""

    for i, char in enumerate(text):
        next_char = text[i + 1] if i < len(text) - 1 else ""

        # è‹±æ•°å­—ã¾ãŸã¯ç‰¹å®šã®è¨˜å·ã§ã‚ã‚Œã° current_word ã«è¿½åŠ 
        if __ENGLISH_WORD_PATTERN.match(char) is not None or char in "-&+'":
            current_word += char
        # ãƒ”ãƒªã‚ªãƒ‰ã®ç‰¹åˆ¥å‡¦ç†
        elif char == ".":
            # å‰å¾ŒãŒè‹±æ•°å­—ã®å ´åˆã¯å˜èªã®ä¸€éƒ¨ã¨ã—ã¦æ‰±ã† (ä¾‹: Node.js)
            if (
                current_word
                and next_char
                and (
                    __ENGLISH_WORD_PATTERN.match(prev_char) is not None
                    and __ENGLISH_WORD_PATTERN.match(next_char) is not None
                )
            ):
                current_word += char
            # ãã‚Œä»¥å¤–ã¯æ–‡ã®åŒºåˆ‡ã‚Šã¨ã—ã¦æ‰±ã† (ä¾‹: I'm fine.)
            else:
                if current_word:
                    words.append(process_english_word(current_word, enable_romaji=True))
                    current_word = ""
                words.append(char)
        else:
            # è‹±å˜èªãŒçµ‚äº†ã—ãŸã‚‰ã‚«ã‚¿ã‚«ãƒŠã«å¤‰æ›ã—ã¦ words ã«è¿½åŠ 
            if current_word:
                words.append(process_english_word(current_word, enable_romaji=True))
                current_word = ""
            words.append(char)

        prev_char = char

    # æœ€å¾Œã®å˜èªã‚’å‡¦ç†
    if current_word:
        words.append(process_english_word(current_word, enable_romaji=True))

    return "".join(words)


def replace_punctuation(text: str) -> str:
    """
    å¥èª­ç‚¹ç­‰ã‚’ã€Œ.ã€ã€Œ,ã€ã€Œ!ã€ã€Œ?ã€ã€Œ'ã€ã€Œ-ã€ã«æ­£è¦åŒ–ã—ã€OpenJTalk ã§èª­ã¿ãŒå–å¾—ã§ãã‚‹ã‚‚ã®ã®ã¿æ®‹ã™ï¼š
    æ¼¢å­—ãƒ»å¹³ä»®åãƒ»ã‚«ã‚¿ã‚«ãƒŠã€æ•°å­—ã€ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã€ã‚®ãƒªã‚·ãƒ£æ–‡å­—

    Args:
        text (str): æ­£è¦åŒ–ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        str: æ­£è¦åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """

    # å¥èª­ç‚¹ã‚’è¾æ›¸ã§ç½®æ›
    replaced_text = __SYMBOL_REPLACE_PATTERN.sub(
        lambda x: __SYMBOL_REPLACE_MAP[x.group()], text
    )

    # ä¸Šè¿°ä»¥å¤–ã®æ–‡å­—ã‚’å‰Šé™¤
    replaced_text = __PUNCTUATION_CLEANUP_PATTERN.sub("", replaced_text)

    return replaced_text


if __name__ == "__main__":
    if len(sys.argv) != 2:
        print(f"Usage: python -m style_bert_vits2.nlp.japanese.normalizer <text>")
        sys.exit(1)
    print(normalize_text(sys.argv[1]))
