#!/usr/bin/env python3
"""
BERT ãƒã‚±ãƒ„åŒ–ã®æ•°å€¤ç²¾åº¦æ¤œè¨¼ãƒ†ã‚¹ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€BERTãƒã‚±ãƒ„åŒ–å‰å¾Œã§ hidden_states ãŒæ•°å€¤çš„ã«ä¸€è‡´ã™ã‚‹ã“ã¨ã‚’æ¤œè¨¼ã™ã‚‹ã€‚
ãƒ¬ãƒ“ãƒ¥ãƒ¼æŒ‡æ‘˜ã‚’å—ã‘ã¦ã€ã€Œç²¾åº¦ã¯çµ¶å¯¾ã«åŠ£åŒ–ã—ãªã„ã€ã‚’å®Ÿè¨¼ã™ã‚‹ãŸã‚ã®ãƒ†ã‚¹ãƒˆã€‚

ä½¿ç”¨æ–¹æ³•:
    .venv/bin/python test_bert_precision.py
"""

import argparse
from pathlib import Path

import numpy as np
import torch
from torch import nn

from style_bert_vits2.constants import Languages
from style_bert_vits2.models.memory_efficient import bucket_bert_inputs
from style_bert_vits2.nlp import bert_models
from style_bert_vits2.nlp.japanese.g2p import text_to_sep_kata


def test_bert_precision(
    device: str = "cuda",
    test_texts: list[str] | None = None,
    tolerance_atol: float = 1e-6,
    tolerance_rtol: float = 1e-6,
) -> dict[str, any]:
    """
    BERTãƒã‚±ãƒ„åŒ–ã®æ•°å€¤ç²¾åº¦æ¤œè¨¼ã‚’å®Ÿè¡Œ

    Args:
        device: æ¨è«–ãƒ‡ãƒã‚¤ã‚¹
        test_texts: ãƒ†ã‚¹ãƒˆç”¨ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆ
        tolerance_atol: çµ¶å¯¾è¨±å®¹èª¤å·®
        tolerance_rtol: ç›¸å¯¾è¨±å®¹èª¤å·®

    Returns:
        æ¤œè¨¼çµæœã®è¾æ›¸
    """

    if test_texts is None:
        test_texts = [
            "ã“ã‚“ã«ã¡ã¯ã€‚",  # 8 â†’ 8 (ãƒã‚±ãƒ„åŒ–ãªã—)
            "ä»Šæ—¥ã¯ã¨ã¦ã‚‚ã„ã„å¤©æ°—ã§ã™ã€‚",  # 15 â†’ 15 (ãƒã‚±ãƒ„åŒ–ãªã—)
            "çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆã§ã™ãŒãƒã‚±ãƒ„åŒ–ãƒ†ã‚¹ãƒˆç”¨ã§ã™",  # 17ãƒˆãƒ¼ã‚¯ãƒ³ç¨‹åº¦ â†’ 32 (ãƒã‚±ãƒ„åŒ–ç™ºç”Ÿ)
            "äººå·¥çŸ¥èƒ½ã®ç™ºå±•ã«ã‚ˆã‚Šã€éŸ³å£°åˆæˆæŠ€è¡“ã‚‚å¤§ããé€²æ­©ã—ã¾ã—ãŸã€‚",  # 30 â†’ 32 (ãƒã‚±ãƒ„åŒ–ç™ºç”Ÿ)
            "æ˜¥ã®è¨ªã‚Œã¨ã¨ã‚‚ã«ã€æ¡œã®èŠ±ãŒå’²ãå§‹ã‚ã¾ã—ãŸã€‚æ·¡ã„ãƒ”ãƒ³ã‚¯è‰²ã®èŠ±ã³ã‚‰ãŒé¢¨ã«èˆã„ã€è¡—å…¨ä½“ãŒè¯ã‚„ã‹ãªé›°å›²æ°—ã«åŒ…ã¾ã‚Œã¦ã„ã¾ã™ã€‚",
            "ãƒ¡ãƒ­ã‚¹ã¯æ¿€æ€’ã—ãŸã€‚å¿…ãšã€ã‹ã®é‚ªæ™ºæš´è™ã®ç‹ã‚’é™¤ã‹ãªã‘ã‚Œã°ãªã‚‰ã¬ã¨æ±ºæ„ã—ãŸã€‚ãƒ¡ãƒ­ã‚¹ã«ã¯æ”¿æ²»ãŒã‚ã‹ã‚‰ã¬ã€‚ãƒ¡ãƒ­ã‚¹ã¯ã€æ‘ã®ç‰§äººã§ã‚ã‚‹ã€‚ç¬›ã‚’å¹ãã€ç¾Šã¨éŠã‚“ã§æš®ã—ã¦æ¥ãŸã€‚",
        ]

    print("=" * 80)
    print("BERT ãƒã‚±ãƒ„åŒ–æ•°å€¤ç²¾åº¦æ¤œè¨¼ãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    print(f"ãƒ‡ãƒã‚¤ã‚¹: {device}")
    print(f"è¨±å®¹èª¤å·®: atol={tolerance_atol}, rtol={tolerance_rtol}")
    print(f"ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æ•°: {len(test_texts)}")
    print("=" * 80)

    # BERT ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    model = bert_models.load_model(Languages.JP, device_map=device, use_fp16=False)
    bert_models.transfer_model(Languages.JP, device)

    results = {
        "total_tests": len(test_texts),
        "passed_tests": 0,
        "failed_tests": 0,
        "test_details": [],
        "overall_passed": True,
    }

    with torch.inference_mode():
        tokenizer = bert_models.load_tokenizer(Languages.JP)

        for i, text in enumerate(test_texts):
            print(f"\nãƒ†ã‚¹ãƒˆ {i + 1}/{len(test_texts)}: {text[:50]}...")

            # ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰å‡¦ç†
            sep_text = text_to_sep_kata(text, raise_yomi_error=False)[0]
            processed_text = "".join(sep_text)

            try:
                # ã‚ªãƒªã‚¸ãƒŠãƒ«ï¼ˆãƒã‚±ãƒ„åŒ–ãªã—ï¼‰
                inputs_original = tokenizer(processed_text, return_tensors="pt")
                for key in inputs_original:
                    inputs_original[key] = inputs_original[key].to(device)

                res_original = model(**inputs_original, output_hidden_states=True)
                hidden_states_original = torch.cat(
                    res_original["hidden_states"][-3:-2], -1
                )[0]

                # ãƒã‚±ãƒ„åŒ–ã‚ã‚Šï¼ˆãƒ†ã‚¹ãƒˆç”¨ã«è©³ç´°æƒ…å ±å‡ºåŠ›ï¼‰
                inputs_bucketed, actual_length = bucket_bert_inputs(
                    {
                        k: v.clone() for k, v in inputs_original.items()
                    },  # deep copyã§ç¢ºå®Ÿãªåˆ†é›¢
                    pool_type="bert_mid_lived",
                    use_pool=False,  # ãƒ†ã‚¹ãƒˆç”¨ã«æ–°è¦ä½œæˆ
                )

                res_bucketed = model(**inputs_bucketed, output_hidden_states=True)
                hidden_states_bucketed = torch.cat(
                    res_bucketed["hidden_states"][-3:-2], -1
                )[0]

                # å®Ÿé•·éƒ¨åˆ†ã®ã¿æ¯”è¼ƒï¼ˆãƒ‘ãƒ‡ã‚£ãƒ³ã‚°éƒ¨åˆ†ã¯é™¤å¤–ï¼‰
                hidden_original_slice = hidden_states_original[:actual_length]
                hidden_bucketed_slice = hidden_states_bucketed[:actual_length]

                # æ•°å€¤ç²¾åº¦æ¤œè¨¼
                is_close = torch.allclose(
                    hidden_original_slice,
                    hidden_bucketed_slice,
                    atol=tolerance_atol,
                    rtol=tolerance_rtol,
                )

                # è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
                abs_diff = torch.abs(hidden_original_slice - hidden_bucketed_slice)
                max_abs_diff = torch.max(abs_diff).item()
                mean_abs_diff = torch.mean(abs_diff).item()

                rel_diff = abs_diff / (torch.abs(hidden_original_slice) + 1e-8)
                max_rel_diff = torch.max(rel_diff).item()
                mean_rel_diff = torch.mean(rel_diff).item()

                test_detail = {
                    "text": text,
                    "token_length": actual_length,
                    "bucket_size": inputs_bucketed["input_ids"].shape[1],
                    "passed": is_close,
                    "max_abs_diff": max_abs_diff,
                    "mean_abs_diff": mean_abs_diff,
                    "max_rel_diff": max_rel_diff,
                    "mean_rel_diff": mean_rel_diff,
                }

                results["test_details"].append(test_detail)

                if is_close:
                    results["passed_tests"] += 1
                    print("  âœ“ PASSED: æ•°å€¤ä¸€è‡´ç¢ºèª")
                else:
                    results["failed_tests"] += 1
                    results["overall_passed"] = False
                    print("  âœ— FAILED: æ•°å€¤ä¸ä¸€è‡´æ¤œå‡º")
                    print(f"    æœ€å¤§çµ¶å¯¾èª¤å·®: {max_abs_diff:.2e}")
                    print(f"    æœ€å¤§ç›¸å¯¾èª¤å·®: {max_rel_diff:.2e}")

                    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±: å„ãƒ†ãƒ³ã‚½ãƒ«ã®è©³ç´°ç¢ºèª
                    print(f"    ãƒ‡ãƒãƒƒã‚°: å…¥åŠ›ã‚­ãƒ¼: {list(inputs_original.keys())}")
                    print(
                        f"    ãƒ‡ãƒãƒƒã‚°: ã‚ªãƒªã‚¸ãƒŠãƒ« attention_mask[:5]: {inputs_original['attention_mask'][0, :5]}"
                    )
                    print(
                        f"    ãƒ‡ãƒãƒƒã‚°: ãƒã‚±ãƒ„åŒ–å¾Œ attention_mask[:5]: {inputs_bucketed['attention_mask'][0, :5]}"
                    )
                    print(
                        f"    ãƒ‡ãƒãƒƒã‚°: ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°éƒ¨åˆ† attention_mask[-5:]: {inputs_bucketed['attention_mask'][0, -5:]}"
                    )
                    if "token_type_ids" in inputs_original:
                        print(
                            f"    ãƒ‡ãƒãƒƒã‚°: ã‚ªãƒªã‚¸ãƒŠãƒ« token_type_ids[:5]: {inputs_original['token_type_ids'][0, :5]}"
                        )
                        print(
                            f"    ãƒ‡ãƒãƒƒã‚°: ãƒã‚±ãƒ„åŒ–å¾Œ token_type_ids[:5]: {inputs_bucketed['token_type_ids'][0, :5]}"
                        )
                        print(
                            f"    ãƒ‡ãƒãƒƒã‚°: ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°éƒ¨åˆ† token_type_ids[-5:]: {inputs_bucketed['token_type_ids'][0, -5:]}"
                        )
                    print(
                        f"    ãƒ‡ãƒãƒƒã‚°: input_idså½¢çŠ¶ original vs bucketed: {inputs_original['input_ids'].shape} vs {inputs_bucketed['input_ids'].shape}"
                    )

                    # BERTãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³IDç¢ºèª
                    pad_token_id = (
                        tokenizer.pad_token_id
                        if tokenizer.pad_token_id is not None
                        else 0
                    )
                    print(f"    ãƒ‡ãƒãƒƒã‚°: ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ID: {pad_token_id}")
                    print(
                        f"    ãƒ‡ãƒãƒƒã‚°: ã‚ªãƒªã‚¸ãƒŠãƒ« input_ids[:5]: {inputs_original['input_ids'][0, :5]}"
                    )
                    print(
                        f"    ãƒ‡ãƒãƒƒã‚°: ãƒã‚±ãƒ„åŒ–å¾Œ input_ids[:5]: {inputs_bucketed['input_ids'][0, :5]}"
                    )
                    print(
                        f"    ãƒ‡ãƒãƒƒã‚°: ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°éƒ¨åˆ† input_ids[-5:]: {inputs_bucketed['input_ids'][0, -5:]}"
                    )

                print(
                    f"  ãƒˆãƒ¼ã‚¯ãƒ³é•·: {actual_length} â†’ ãƒã‚±ãƒ„ã‚µã‚¤ã‚º: {inputs_bucketed['input_ids'].shape[1]}"
                )
                print(
                    f"  å¹³å‡çµ¶å¯¾èª¤å·®: {mean_abs_diff:.2e}, æœ€å¤§çµ¶å¯¾èª¤å·®: {max_abs_diff:.2e}"
                )
                print(
                    f"  å¹³å‡ç›¸å¯¾èª¤å·®: {mean_rel_diff:.2e}, æœ€å¤§ç›¸å¯¾èª¤å·®: {max_rel_diff:.2e}"
                )

            except Exception as e:
                print(f"  âœ— ERROR: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
                results["failed_tests"] += 1
                results["overall_passed"] = False
                results["test_details"].append(
                    {
                        "text": text,
                        "passed": False,
                        "error": str(e),
                    }
                )

    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 80)
    print("ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 80)
    print(f"ç·ãƒ†ã‚¹ãƒˆæ•°: {results['total_tests']}")
    print(f"æˆåŠŸ: {results['passed_tests']}")
    print(f"å¤±æ•—: {results['failed_tests']}")

    if results["overall_passed"]:
        print("\nğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒåˆæ ¼ã—ã¾ã—ãŸï¼")
        print("   BERTãƒã‚±ãƒ„åŒ–ã«ã‚ˆã‚‹æ•°å€¤ç²¾åº¦ã¸ã®å½±éŸ¿ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        print("\nâš ï¸  ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
        print("   å®Ÿè£…ã®è¦‹ç›´ã—ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚")

    # çµ±è¨ˆæƒ…å ±
    if results["test_details"]:
        passed_details = [d for d in results["test_details"] if d.get("passed", False)]
        if passed_details:
            max_abs_diffs = [
                d["max_abs_diff"] for d in passed_details if "max_abs_diff" in d
            ]
            max_rel_diffs = [
                d["max_rel_diff"] for d in passed_details if "max_rel_diff" in d
            ]

            if max_abs_diffs and max_rel_diffs:
                print("\næˆåŠŸãƒ†ã‚¹ãƒˆã®èª¤å·®ç¯„å›²:")
                print(
                    f"  çµ¶å¯¾èª¤å·®: æœ€å¤§ {max(max_abs_diffs):.2e}, å¹³å‡ {np.mean(max_abs_diffs):.2e}"
                )
                print(
                    f"  ç›¸å¯¾èª¤å·®: æœ€å¤§ {max(max_rel_diffs):.2e}, å¹³å‡ {np.mean(max_rel_diffs):.2e}"
                )

    return results


def main():
    parser = argparse.ArgumentParser(description="BERT ãƒã‚±ãƒ„åŒ–æ•°å€¤ç²¾åº¦æ¤œè¨¼")
    parser.add_argument(
        "--device",
        type=str,
        default="cuda",
        choices=["cpu", "cuda"],
        help="æ¨è«–ãƒ‡ãƒã‚¤ã‚¹ (default: cuda)",
    )
    parser.add_argument(
        "--atol", type=float, default=1e-6, help="çµ¶å¯¾è¨±å®¹èª¤å·® (default: 1e-6)"
    )
    parser.add_argument(
        "--rtol", type=float, default=1e-6, help="ç›¸å¯¾è¨±å®¹èª¤å·® (default: 1e-6)"
    )

    args = parser.parse_args()

    try:
        results = test_bert_precision(
            device=args.device,
            tolerance_atol=args.atol,
            tolerance_rtol=args.rtol,
        )

        # çµæœã‚’çµ‚äº†ã‚³ãƒ¼ãƒ‰ã§è¿”ã™
        exit_code = 0 if results["overall_passed"] else 1
        exit(exit_code)

    except KeyboardInterrupt:
        print("\nãƒ†ã‚¹ãƒˆãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
        exit(1)
    except Exception as e:
        print(f"\nãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        exit(1)


if __name__ == "__main__":
    main()
